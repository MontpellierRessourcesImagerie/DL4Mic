2020-07-01 18:00:13.146637: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-07-01 18:00:13.182033: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2020-07-01 18:00:13.182610: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f612862c50 executing computations on platform Host. Devices:
2020-07-01 18:00:13.182640: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-07-01 18:00:13.182875: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /media/baecker/DONNEES1/programs/fiji-linux64/Fiji.app/lib/linux64:/media/baecker/DONNEES1/programs/fiji-linux64/Fiji.app/mm/linux64
2020-07-01 18:00:13.182885: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2020-07-01 18:00:13.182912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (orion): /proc/driver/nvidia/version does not exist
2020-07-01 18:00:13.265779: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Preparing validation data:   0%|          | 0/43 [00:00<?, ?it/s]Preparing validation data:  88%|████████▊ | 38/43 [00:00<00:00, 377.91it/s]Preparing validation data: 100%|██████████| 43/43 [00:00<00:00, 376.06it/s]Namespace(baseDir='../../models', batchSize=128, dataPath='../../n2v-data/training', epochs=4, learningRate=0.0004, n2vPercPix=1.6, name='new_n2v_model', netDepth=2, netKernelSize=3, noAugment=True, patchSizeXY=64, stepsPerEpoch=0, unetNFirst=32, validationFraction=10.0)
You do not have GPU access.
Expect slow performance.
Available devices:
name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 3409245296397818514

name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 12953215850444447286
physical_device_desc: "device: XLA_CPU device"

Using Tensorflow version  1.14.0
Generated patches: (144, 64, 64, 1)
Generated patches: (144, 64, 64, 1)
Generated patches: (144, 64, 64, 1)
432 patches created.
43 patch images for validation ( 10.0 %).
346 patch images for training.
4
{'means': ['78.8545'], 'stds': ['20.96585'], 'n_dim': 2, 'axes': 'YXC', 'n_channel_in': 1, 'n_channel_out': 1, 'unet_residual': False, 'unet_n_depth': 2, 'unet_kern_size': 3, 'unet_n_first': 32, 'unet_last_activation': 'linear', 'unet_input_shape': (None, None, 1), 'train_loss': 'mse', 'train_epochs': 4, 'train_steps_per_epoch': 4, 'train_learning_rate': 0.0004, 'train_batch_size': 128, 'train_tensorboard': True, 'train_checkpoint': 'weights_best.h5', 'train_reduce_lr': {'factor': 0.5, 'patience': 10}, 'batch_norm': True, 'n2v_perc_pix': 1.6, 'n2v_patch_shape': (64, 64), 'n2v_manipulator': 'uniform_withCP', 'n2v_neighborhood_radius': 5, 'probabilistic': False}
Setup done.
N2VConfig(axes='YXC', batch_norm=True, means=['78.8545'], n2v_manipulator='uniform_withCP', n2v_neighborhood_radius=5, n2v_patch_shape=(64, 64), n2v_perc_pix=1.6, n_channel_in=1, n_channel_out=1, n_dim=2, probabilistic=False, stds=['20.96585'], train_batch_size=128, train_checkpoint='weights_best.h5', train_epochs=4, train_learning_rate=0.0004, train_loss='mse', train_reduce_lr={'factor': 0.5, 'patience': 10}, train_steps_per_epoch=4, train_tensorboard=True, unet_input_shape=(None, None, 1), unet_kern_size=3, unet_last_activation='linear', unet_n_depth=2, unet_n_first=32, unet_residual=False)
65 blind-spots will be generated per training patch of size (64, 64).
Epoch 1/4

1/4 [======>.......................] - ETA: 18s - loss: 1.1748 - n2v_mse: 1.1748 - n2v_abs: 0.8145
2/4 [==============>...............] - ETA: 11s - loss: 0.9797 - n2v_mse: 0.9797 - n2v_abs: 0.7379
3/4 [=====================>........] - ETA: 5s - loss: 0.8695 - n2v_mse: 0.8695 - n2v_abs: 0.6930 
4/4 [==============================] - 17s 4s/step - loss: 0.8429 - n2v_mse: 0.8429 - n2v_abs: 0.6737 - val_loss: 1.4445 - val_n2v_mse: 1.4445 - val_n2v_abs: 0.6927
Epoch 2/4

1/4 [======>.......................] - ETA: 13s - loss: 0.5456 - n2v_mse: 0.5456 - n2v_abs: 0.5697
2/4 [==============>...............] - ETA: 4s - loss: 0.5498 - n2v_mse: 0.5498 - n2v_abs: 0.5681 
3/4 [=====================>........] - ETA: 3s - loss: 0.5240 - n2v_mse: 0.5240 - n2v_abs: 0.5569
4/4 [==============================] - 15s 4s/step - loss: 0.5070 - n2v_mse: 0.5070 - n2v_abs: 0.5453 - val_loss: 0.6541 - val_n2v_mse: 0.6541 - val_n2v_abs: 0.5523
Epoch 3/4

1/4 [======>.......................] - ETA: 38s - loss: 0.4122 - n2v_mse: 0.4122 - n2v_abs: 0.4874
2/4 [==============>...............] - ETA: 26s - loss: 0.4127 - n2v_mse: 0.4127 - n2v_abs: 0.4873
3/4 [=====================>........] - ETA: 8s - loss: 0.3905 - n2v_mse: 0.3905 - n2v_abs: 0.4746 
4/4 [==============================] - 41s 10s/step - loss: 0.3872 - n2v_mse: 0.3872 - n2v_abs: 0.4719 - val_loss: 0.8040 - val_n2v_mse: 0.8040 - val_n2v_abs: 0.5582
Epoch 4/4

1/4 [======>.......................] - ETA: 27s - loss: 0.3180 - n2v_mse: 0.3180 - n2v_abs: 0.4344
2/4 [==============>...............] - ETA: 9s - loss: 0.3105 - n2v_mse: 0.3105 - n2v_abs: 0.4401 
3/4 [=====================>........] - ETA: 6s - loss: 0.3077 - n2v_mse: 0.3077 - n2v_abs: 0.4341
4/4 [==============================] - 31s 8s/step - loss: 0.3083 - n2v_mse: 0.3083 - n2v_abs: 0.4312 - val_loss: 0.6958 - val_n2v_mse: 0.6958 - val_n2v_abs: 0.5336


Loading network weights from 'weights_best.h5'.
Training done.
loss 0.309516510727473 validation loss 0.6958045363426208
Time elapsed: 0.0 hour(s) 1.0 min(s) 50 sec(s)
---training done---
