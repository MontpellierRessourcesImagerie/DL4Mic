2020-09-03 11:44:35.460542: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-09-03 11:44:35.493007: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2020-09-03 11:44:35.493620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ae7a0647f0 executing computations on platform Host. Devices:
2020-09-03 11:44:35.493639: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-09-03 11:44:35.493892: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /media/baecker/DONNEES1/programs/fiji-linux64/Fiji.app/lib/linux64:/media/baecker/DONNEES1/programs/fiji-linux64/Fiji.app/mm/linux64
2020-09-03 11:44:35.493903: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)
2020-09-03 11:44:35.493940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (orion): /proc/driver/nvidia/version does not exist
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/baecker/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-09-03 11:44:46.680451: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-09-03 11:44:53.243919: W tensorflow/core/framework/allocator.cc:107] Allocation of 1207959552 exceeds 10% of system memory.
2020-09-03 11:44:53.251654: W tensorflow/core/framework/allocator.cc:107] Allocation of 1207959552 exceeds 10% of system memory.
Namespace(baseDir='../../models', batchSize=4, dataSourcePath='../../unet-data/training/source', dataTargetPath='../../unet-data/training/target', epochs=10, horizontalFlip=True, horizontalShift=10, learningRate=0.001, name='new_unet2D_model', patchSizeXY=512, poolingSteps=2, rotationRange=180, shearRange=10, stepsPerEpoch=3, useDataAugmentation=True, validationFraction=10.0, verticalFlip=True, verticalShift=20, zoomRange=10)
You do not have GPU access.
Expect slow performance.
Tensorflow version is 1.14.0
Creating patches...
number of patches: 200
[31m!! WARNING: Folder already exists and will be overwritten !![0m
Getting class weights...
HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 512, 512, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 512, 512, 64) 640         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 256, 256, 128 147584      conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 128, 128, 256 590080      conv2d_5[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 256, 256, 128 131200      up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 256, 256, 256 0           conv2d_4[0][0]                   
                                                                 conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 256, 256, 128 295040      concatenate_1[0][0]              
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 512, 512, 64) 32832       up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 512, 512, 128 0           conv2d_2[0][0]                   
                                                                 conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 512, 512, 2)  1154        conv2d_11[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 512, 512, 1)  3           conv2d_12[0][0]                  
==================================================================================================
Total params: 1,715,205
Trainable params: 1,715,205
Non-trainable params: 0
__________________________________________________________________________________________________
{'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}
[31m!! WARNING: Model folder already existed and has been removed !![0m
---------------------------- Main training parameters ----------------------------
Number of epochs: 10
Batch size: 4
Number of training dataset: 200
Number of training steps: 3
Number of validation steps: 5
---------------------------- ------------------------ ----------------------------
Epoch 1/10
Found 180 images belonging to 1 classes.
Found 20 images belonging to 1 classes.
Found 20 images belonging to 1 classes.
Found 180 images belonging to 1 classes.
1/3 [=========>....................] - ETA: 28s - loss: 0.65882020-09-03 11:45:06.268520: W tensorflow/core/framework/allocator.cc:107] Allocation of 1207959552 exceeds 10% of system memory.
2020-09-03 11:45:06.268520: W tensorflow/core/framework/allocator.cc:107] Allocation of 1207959552 exceeds 10% of system memory.
2/3 [===================>..........] - ETA: 13s - loss: 3.56192020-09-03 11:45:19.243804: W tensorflow/core/framework/allocator.cc:107] Allocation of 1207959552 exceeds 10% of system memory.
3/3 [==============================] - 58s 19s/step - loss: 2.6070 - val_loss: 0.7058

Epoch 00001: val_loss improved from inf to 0.70584, saving model to ../../models/new_unet2D_model/weights_best.hdf5
Epoch 2/10
1/3 [=========>....................] - ETA: 26s - loss: 0.70322/3 [===================>..........] - ETA: 13s - loss: 0.67893/3 [==============================] - 58s 19s/step - loss: 0.6805 - val_loss: 0.6998

Epoch 00002: val_loss improved from 0.70584 to 0.69977, saving model to ../../models/new_unet2D_model/weights_best.hdf5
Epoch 3/10
1/3 [=========>....................] - ETA: 26s - loss: 0.68662/3 [===================>..........] - ETA: 13s - loss: 0.70163/3 [==============================] - 58s 19s/step - loss: 0.7286 - val_loss: 0.7071

Epoch 00003: val_loss did not improve from 0.69977
Epoch 4/10
1/3 [=========>....................] - ETA: 26s - loss: 0.72272/3 [===================>..........] - ETA: 13s - loss: 0.73573/3 [==============================] - 59s 20s/step - loss: 0.7216 - val_loss: 0.6922

Epoch 00004: val_loss improved from 0.69977 to 0.69220, saving model to ../../models/new_unet2D_model/weights_best.hdf5
Epoch 5/10
1/3 [=========>....................] - ETA: 27s - loss: 0.66852/3 [===================>..........] - ETA: 14s - loss: 0.68823/3 [==============================] - 60s 20s/step - loss: 0.6919 - val_loss: 0.6998

Epoch 00005: val_loss did not improve from 0.69220
Epoch 6/10
1/3 [=========>....................] - ETA: 28s - loss: 0.70632/3 [===================>..........] - ETA: 14s - loss: 0.70353/3 [==============================] - 60s 20s/step - loss: 0.7071 - val_loss: 0.7010

Epoch 00006: val_loss did not improve from 0.69220
Epoch 7/10
1/3 [=========>....................] - ETA: 27s - loss: 0.70422/3 [===================>..........] - ETA: 13s - loss: 0.72293/3 [==============================] - 59s 20s/step - loss: 0.7143 - val_loss: 0.7079

Epoch 00007: val_loss did not improve from 0.69220
Epoch 8/10
1/3 [=========>....................] - ETA: 27s - loss: 0.66942/3 [===================>..........] - ETA: 13s - loss: 0.68283/3 [==============================] - 58s 19s/step - loss: 0.6669 - val_loss: 0.7131

Epoch 00008: val_loss did not improve from 0.69220
Epoch 9/10
1/3 [=========>....................] - ETA: 27s - loss: 0.70212/3 [===================>..........] - ETA: 13s - loss: 0.71623/3 [==============================] - 58s 19s/step - loss: 0.6988 - val_loss: 0.6999

Epoch 00009: val_loss did not improve from 0.69220
Epoch 10/10
1/3 [=========>....................] - ETA: 27s - loss: 0.73572/3 [===================>..........] - ETA: 14s - loss: 0.73463/3 [==============================] - 59s 20s/step - loss: 0.7079 - val_loss: 0.7082

Epoch 00010: val_loss did not improve from 0.69220
------------------------------------------
Time elapsed: 0.0 hour(s) 9.0 min(s) 47 sec(s)
------------------------------------------
---training done---
